{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b160a636-227c-4585-8a61-036d76e7c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment this if you are not using AIT proxy...\n",
    "import os\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05065402-a1fc-41cf-bab6-89f997182e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import utils\n",
    "# Set the random seed for reproducible experiments\n",
    "random.seed(230)\n",
    "torch.manual_seed(230)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e274550-a7f6-4ca1-b5c7-194e1bf58d19",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "\n",
    "Reference : https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#iterative-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55599e9-5c27-4560-b5f2-b2a08a70f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a935c3-e987-4936-8051-2d5c5367200e",
   "metadata": {},
   "source": [
    "## 1.Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc40503c-23e6-445b-9585-18c1c624d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1185.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "task_name = \"sst2\"\n",
    "datasets = load_dataset(\"glue\",task_name)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ab4b0-987f-4b16-a079-91bff7c97b33",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cbfd60-0c8d-4505-9f50-f064bfe123b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = \"distilroberta-base\"\n",
    "teacher = \"textattack/roberta-base-SST-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c247d6-b759-4198-a808-4b60454c4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c99035-7527-40ee-b273-af24a56202bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "if task_name is not None:\n",
    "    is_regression = task_name == \"stsb\"\n",
    "    if not is_regression:\n",
    "        label_list = datasets[\"train\"].features[\"label\"].names\n",
    "        num_labels = len(label_list)\n",
    "    else:\n",
    "        num_labels = 1\n",
    "else:\n",
    "    # Trying to have good defaults here, don't hesitate to tweak to your needs.\n",
    "    is_regression = datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]\n",
    "    if is_regression:\n",
    "        num_labels = 1\n",
    "    else:\n",
    "        # A useful fast method:\n",
    "        # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n",
    "        label_list = datasets[\"train\"].unique(\"label\")\n",
    "        label_list.sort()  # Let's sort it for determinism\n",
    "        num_labels = len(label_list)\n",
    "        \n",
    "num_labels, is_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05fda63f-8e6c-4b7c-b08d-d673310fc53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer, PretrainedConfig\n",
    "model_name_or_path = student\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    num_labels=num_labels, \n",
    "    finetuning_task=task_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config=config,\n",
    ") #student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35da97a1-5587-49da-8164-4c3bda5cc5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ddce3eb30c7f5991.arrow\n",
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d03df3660f5ad304.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id = None\n",
    "\n",
    "if (\n",
    "    model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id\n",
    "    and task_name is not None\n",
    "    and not is_regression\n",
    "):\n",
    "    # Some have all caps in their config, some don't.\n",
    "    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "    if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):\n",
    "        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "        \n",
    "elif task_name is None and not is_regression:\n",
    "    label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "    \n",
    "def tokenize_function(examples):\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "    args = (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    result = tokenizer(*args, max_length=180, padding=\"max_length\", truncation=True)\n",
    "    if \"label\" in examples:\n",
    "        if label_to_id is not None:\n",
    "            # Map labels to IDs (not necessary for GLUE tasks)\n",
    "            result[\"label\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "        else:\n",
    "            # In all cases, rename the column to labels because the model will expect that.\n",
    "            result[\"label\"] = examples[\"label\"]\n",
    "    \n",
    "    return result\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d25543-1bf0-49fe-be84-220ecb5a0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use list comprehension to extract non-None elements from the tuple\n",
    "elements = [element for element in task_to_keys[task_name] if element is not None]\n",
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1de45bf0-7dd2-42ae-91fb-e25c0515b37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 tokenized_datasets = tokenized_datasets.remove_columns(elements + [<span style=\"color: #808000; text-decoration-color: #808000\">\"idx\"</span>])                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>tokenized_datasets = tokenized_datasets.rename_column(<span style=\"color: #808000; text-decoration-color: #808000\">\"label\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>tokenized_datasets.set_format(<span style=\"color: #808000; text-decoration-color: #808000\">\"torch\"</span>)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>tokenized_datasets                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'elements'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 tokenized_datasets = tokenized_datasets.remove_columns(elements + [\u001b[33m\"\u001b[0m\u001b[33midx\u001b[0m\u001b[33m\"\u001b[0m])                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mtokenized_datasets = tokenized_datasets.rename_column(\u001b[33m\"\u001b[0m\u001b[33mlabel\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mtokenized_datasets.set_format(\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mtokenized_datasets                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'elements'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(elements + [\"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c79c98-9914-4cfb-bbd7-83d99ae00e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=55) #.select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation_matched\" if task_name == \"mnli\" else \"validation\"].shuffle(seed=55)\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3dec7c-587c-4185-9de7-fb16bae432fb",
   "metadata": {},
   "source": [
    "## 3. Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601b098-8c1e-4b22-a461-8478fe6c9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "per_device_train_batch_size = 16\n",
    "per_device_eval_batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=per_device_train_batch_size)\n",
    "val_dataloader = DataLoader(small_eval_dataset, batch_size=per_device_eval_batch_size)\n",
    "test_dataloader = DataLoader(small_test_dataset, batch_size=per_device_eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e1142-731d-406f-83b1-60f9a2499d76",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef9126-3175-46cb-a618-5afaa5f93c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher model\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# student model\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student,\n",
    "    config=config,\n",
    ")\n",
    "student_model.train()\n",
    "teacher_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "081f257e-3b27-4d8d-9ea2-7dde0719d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_checkpoint = 'experiments/best.pth.tar'\n",
    "checkpoint = utils.load_checkpoint(teacher_checkpoint, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ae9e9ce-d33b-4f7a-ac5f-0aa25c454b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(list(model.named_modules()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671faa4-2635-417c-a15d-e4b0b630ca2c",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8c0f9-7d21-4801-a100-072e224cd0bc",
   "metadata": {},
   "source": [
    "## Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b00de20-e5a1-470b-b6a5-9858fc9d1637",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teacher_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define optimizer\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m teacher_optimizer \u001b[38;5;241m=\u001b[39m AdamW(\u001b[43mteacher_model\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[1;32m      5\u001b[0m student_optimizer \u001b[38;5;241m=\u001b[39m AdamW(student_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6e-5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teacher_model' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define optimizer\n",
    "teacher_optimizer = AdamW(teacher_model.parameters(), lr=5e-5)\n",
    "student_optimizer = AdamW(student_model.parameters(), lr=6e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a52ffb-1a61-49f1-8f9a-defbc4ef38ce",
   "metadata": {},
   "source": [
    "## Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100c9a0-50d7-4043-b5c3-4433556929e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "teacher_model, teacher_optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    student_model, teacher_optimizer, train_dataloader, val_dataloader\n",
    ")\n",
    "# teacher_model = accelerator.prepare(teacher_model)\n",
    "\n",
    "student_model, student_optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    student_model, student_optimizer, train_dataloader, val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c271ec-c39f-403c-8df3-873d285ab1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "import math\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "num_update_steps_per_epoch = math.ceil(\n",
    "        len(train_dataloader) / gradient_accumulation_steps\n",
    "    )\n",
    "\n",
    "num_train_epochs = 10\n",
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "teacher_lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=teacher_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_train_steps,\n",
    ")\n",
    "\n",
    "student_lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=student_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_train_steps,\n",
    ")\n",
    "\n",
    "total_batch_size = (\n",
    "        per_device_train_batch_size\n",
    "        * accelerator.num_processes\n",
    "        * gradient_accumulation_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fe760-dbb9-411f-8d56-7f1dda6bdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Private Tranformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c55c2-7162-4abf-bd18-8bcccaeeb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ml_swissknife\n",
    "# !pip install opt_einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d2bb3-2001-4d61-b94e-de0330ee1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers, torch\n",
    "from private_transformers import PrivacyEngine\n",
    "dp = True\n",
    "if dp == True:\n",
    "    #Student Model\n",
    "    privacy_engine = PrivacyEngine(\n",
    "        student_model,\n",
    "        batch_size=per_device_train_batch_size,\n",
    "        sample_size=len(datasets['train']),\n",
    "        epochs=per_device_train_batch_size,\n",
    "        max_grad_norm=0.1,\n",
    "        target_epsilon=3,\n",
    "        clipping_mode=\"ghost\",  # The only change you need to make!\n",
    "    )\n",
    "    privacy_engine.attach(student_optimizer)\n",
    "    #Teacher Model\n",
    "    privacy_engine = PrivacyEngine(\n",
    "        teacher_model,\n",
    "        batch_size=per_device_train_batch_size,\n",
    "        sample_size=len(datasets['train']),\n",
    "        epochs=per_device_train_batch_size,\n",
    "        max_grad_norm=0.1,\n",
    "        target_epsilon=3,\n",
    "        clipping_mode=\"ghost\",  # The only change you need to make!\n",
    "    )\n",
    "    privacy_engine.attach(teacher_optimizer)\n",
    "else :\n",
    "    privacy_engine = None\n",
    "\n",
    "privacy_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a927b7-d510-4b9a-b3db-49eab31b3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss Objective \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e78818-f5f1-4311-81cb-04c912251ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the cross entropy loss given outputs and labels.\n",
    "\n",
    "    Returns:\n",
    "        loss (Variable): cross entropy loss for all images in the batch\n",
    "\n",
    "    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n",
    "          demonstrates how you can easily define a custom loss function.\n",
    "    \"\"\"\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e9781-b492-43af-9c1a-a79e9dd9caf4",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168ed91-e1d5-4e9c-b64a-d2038c2336fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the accuracy, given the outputs and labels for all images.\n",
    "\n",
    "    Args:\n",
    "        outputs: (np.ndarray) output of the model\n",
    "        labels: (np.ndarray) [0, 1, ..., num_classes-1]\n",
    "\n",
    "    Returns: (float) accuracy in [0,1]\n",
    "    \"\"\"\n",
    "    # outputs = np.argmax(outputs, axis=1)\n",
    "    return np.sum(outputs==labels)/float(labels.size)\n",
    "\n",
    "\n",
    "# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    # could add more metrics such as accuracy for each token type\n",
    "}\n",
    "\n",
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.total/float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83aa67-a342-474d-917f-68dd18135792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking chucking\n",
    "for i in train_dataloader:\n",
    "    print(i['input_ids'].shape, i['labels'].shape)\n",
    "    break\n",
    "for i in val_dataloader:\n",
    "    print(i['input_ids'].shape, i['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ae6a4-4af4-4415-9a03-bf29f901b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, dataloader, metrics, params):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = RunningAverage()\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        # batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # compute model output, fetch teacher output, and compute KD loss\n",
    "        output_batch = model(**batch) # output = loss, logits, hidden_states, attentions\n",
    "        labels_batch = batch['labels']\n",
    "\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "        loss = loss.reshape(-1)\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        \n",
    "        # This step is different from existing workflows: \n",
    "        # Don't call `loss.backward`; leave it to `optimizer.step` to handle backward.\n",
    "        # performs updates using calculated gradients\n",
    "        # `loss` is a 1-D tensor of shape (batch_size,).\n",
    "        optimizer.step(loss=loss)\n",
    "\n",
    "        # Evaluate summaries only once in a while\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            # extract data from torch, move to cpu, convert to numpy arrays            \n",
    "            output_batch = output_batch.logits.argmax(dim=-1).cpu().numpy()\n",
    "            labels_batch = labels_batch.cpu().numpy()\n",
    "\n",
    "            # compute all metrics on this batch\n",
    "            summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
    "                             for metric in metrics}\n",
    "            summary_batch['loss'] = loss.item()\n",
    "            summ.append(summary_batch)\n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        \n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d1743-4465-4a74-acef-c0c0bd83b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, dataloader, metrics):\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    # summary for current eval loop\n",
    "    summ = []\n",
    "\n",
    "    # compute metrics over the dataset\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        \n",
    "        # compute model output\n",
    "        output_batch = model(**batch)\n",
    "        labels_batch = batch['labels']\n",
    "        \n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # extract data from torch, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.logits.argmax(dim=-1).cpu().numpy()\n",
    "        labels_batch = labels_batch.cpu().numpy()\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        summary_batch['loss'] = loss.item()\n",
    "        # summary_batch['loss'] = loss\n",
    "        summ.append(summary_batch)\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    print(\"- Eval metrics : \" + metrics_string)\n",
    "    return metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813014d-7ca3-4d62-a01e-e7ffa966bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n",
    "                       loss_fn, metrics, model_dir, restore_file=None):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_train_epochs):\n",
    "        student_lr_scheduler.step()\n",
    "        \n",
    "         # compute number of batches in one epoch (one full pass over the training set)\n",
    "        train(model, optimizer, loss_fn_kd, train_dataloader,\n",
    "                 metrics)\n",
    "\n",
    "        # Evaluate for one epoch on validation set\n",
    "        val_metrics = evaluate(model, val_dataloader, metrics)\n",
    "\n",
    "        val_acc = val_metrics['accuracy']\n",
    "        is_best = val_acc>=best_val_acc\n",
    "        \n",
    "        # Save weights\n",
    "        utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optim_dict' : optimizer.state_dict()},\n",
    "                               is_best=is_best,\n",
    "                               checkpoint=model_dir)\n",
    "        print(f'epoch: {epoch + 1}')\n",
    "        # If best_eval, best_save_path\n",
    "        if is_best:\n",
    "            print(\"- Found new best accuracy\")\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "            # Save best val metrics in a json file in the model directory\n",
    "            best_json_path = os.path.join(model_dir, \"metrics_val_best_weights.json\")\n",
    "            utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "        # Save latest val metrics in a json file in the model directory\n",
    "        last_json_path = os.path.join(model_dir, \"metrics_val_last_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, last_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8663ca-dd03-4cf2-834b-6ab7ca613e0c",
   "metadata": {},
   "source": [
    "## Structured DPIMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414552a-90a6-4231-8031-e038f4950d46",
   "metadata": {},
   "source": [
    "![Structured DPIMP](images/Structured_DPIMP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d56a60-b268-494b-a812-d04266123fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def structured_DPIMP(T, L, alpha, N, M):\n",
    "    S = T.clone()  # Assuming T and S are PyTorch model instances\n",
    "    \n",
    "    for j in range(1, L + 1):\n",
    "        # Fine-tune S for N iterations with DPSGD\n",
    "        for _ in range(N):\n",
    "            # Perform DPSGD training here\n",
    "            train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n",
    "                       loss_fn, metrics, model_dir, restore_file=None):\n",
    "        \n",
    "        remaining_weights = []\n",
    "        for param in S.parameters():\n",
    "            remaining_weights.extend(param.view(-1).detach().numpy())\n",
    "        \n",
    "        # Set Wmin consisting of alpha% of the remaining model weights with the least magnitude\n",
    "        num_to_keep = int(alpha * len(remaining_weights))\n",
    "        Wmin_indices = np.argpartition(np.abs(remaining_weights), num_to_keep)[:num_to_keep]\n",
    "        Wmin = [remaining_weights[i] for i in Wmin_indices]\n",
    "        \n",
    "        for i, param in enumerate(S.parameters()):\n",
    "            Wi = param.view(-1).detach().numpy()\n",
    "            intersection = np.intersect1d(Wi, Wmin)\n",
    "            if len(intersection) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Drop the layer i* from S\n",
    "            i_star = np.argmax([np.sum(Wi == val) for val in intersection])\n",
    "            # You might want to handle removing the corresponding layer in the model architecture\n",
    "            \n",
    "        # Fine-tune S for M more iterations with DPSGD\n",
    "        for _ in range(M):\n",
    "            # Perform DPSGD training here\n",
    "            train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n",
    "                       loss_fn, metrics, model_dir, restore_file=None):\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621735dc-a595-4df7-9993-ed788311132c",
   "metadata": {},
   "source": [
    "## Unstructured DPIMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59aa566-084b-486b-86c1-1c3c3be8d292",
   "metadata": {},
   "source": [
    "![Unstructured DPIMP](images/Unstructured_DPIMP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc08978-7394-4dfe-aebf-64f0115e85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def unstructured_DPIMP(T, sparsity, alpha, N, M):\n",
    "    S = T.clone()  # Assuming T and S are PyTorch model instances\n",
    "    \n",
    "    total_params = sum(p.numel() for p in T.parameters())\n",
    "    num_iterations = int(np.ceil(sparsity / alpha))\n",
    "    \n",
    "    T_prime = T.clone()\n",
    "    \n",
    "    for i in range(1, num_iterations + 1):\n",
    "        # Fine-tune T' for N iterations with DPSGD\n",
    "        for _ in range(N):\n",
    "            # Perform DPSGD training here\n",
    "            train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n",
    "                       loss_fn, metrics, model_dir, restore_file=None):\n",
    "        \n",
    "        # Prune (alpha * i)% of weights with the lowest magnitude from T'\n",
    "        num_params_to_prune = int(alpha * i * total_params)\n",
    "        all_weights = np.concatenate([param.view(-1).detach().numpy() for param in T_prime.parameters()])\n",
    "        sorted_indices = np.argsort(np.abs(all_weights))\n",
    "        prune_indices = sorted_indices[:num_params_to_prune]\n",
    "        \n",
    "        for param in T_prime.parameters():\n",
    "            flat_param = param.view(-1).detach().numpy()\n",
    "            flat_param[prune_indices] = 0\n",
    "            param.data = torch.from_numpy(flat_param).reshape(param.shape)\n",
    "        \n",
    "        # Reset the non-zero weights of T' to the original T\n",
    "        for param_s, param_t in zip(S.parameters(), T.parameters()):\n",
    "            if param_t.requires_grad:\n",
    "                param_s.data = param_t.data.clone()\n",
    "        \n",
    "    # Fine-tune T' for M iterations with DPSGD\n",
    "    for _ in range(M):\n",
    "        # Perform DPSGD training here\n",
    "        train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n",
    "                       loss_fn, metrics, model_dir, restore_file=None):\n",
    "        \n",
    "    return S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
