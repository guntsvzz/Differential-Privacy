{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfaaa2d-2f19-4f72-8bed-d86eb10dd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment this if you are not using AIT proxy...\n",
    "import os\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c28875a-2da0-4a37-8bad-00cf110c1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf35958-077b-4563-90a4-01084742dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import open\n",
    "import torch\n",
    "import json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad5c2fc-6fed-43a8-830d-69a5bfe6e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbc352-6296-481c-aafa-df0fe8b0d63c",
   "metadata": {},
   "source": [
    "## 1.Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5677b1-34b1-49dd-b6df-f7ff99c87082",
   "metadata": {},
   "source": [
    "### Preprocessing the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e348a0b-e428-4f8b-8a8f-17ae55a45c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c449fcf3-1128-4d87-ac66-307a5c4a6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "# PAD_TOKEN = '<pad>'\n",
    "# tokenizer.add_special_tokens({'pad_token': PAD_TOKEN})\n",
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f14f80-62fa-4fb1-aba5-437253dadac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wikitext_Dataset:\n",
    "    def __init__(self, path):\n",
    "        self.train = os.path.join(path, 'train/train.txt')\n",
    "        self.valid = os.path.join(path, 'valid/valid.txt')\n",
    "        self.test  = os.path.join(path, 'test/test.txt')\n",
    "\n",
    "    def build_corpus(self, path):\n",
    "        files = open(path,'r')\n",
    "        lines = []\n",
    "        for line in files:\n",
    "            line = line.strip().lower()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            lines.append(line)\n",
    "        return lines\n",
    "path_files = './data/wikitext-2-add10b'\n",
    "corpus = Wikitext_Dataset(path_files)\n",
    "train_dataset = corpus.build_corpus(corpus.train)\n",
    "valid_dataset = corpus.build_corpus(corpus.valid)\n",
    "test_dataset  = corpus.build_corpus(corpus.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4695bc39-2485-43d3-b157-795cf36b1b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 23777\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2461\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "raw_datasets_train = Dataset.from_pandas(pd.DataFrame(data = {'text': train_dataset}))\n",
    "raw_datasets_valid = Dataset.from_pandas(pd.DataFrame(data = {'text': valid_dataset}))\n",
    "raw_datasets_test  = Dataset.from_pandas(pd.DataFrame(data = {'text': test_dataset}))\n",
    "#remove .shuffle if you want to train the whole dataset....\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        'train':raw_datasets_train,\n",
    "        'validation':raw_datasets_valid,\n",
    "        'test':raw_datasets_test\n",
    "    }\n",
    ")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb57088-b3b7-4be0-9977-8f1157626113",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26741d7f-f7fd-4841-b99a-fdc6cd48c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 23777\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 2461\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 2891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we tokenize all the texts.\n",
    "column_names = raw_datasets[\"train\"].column_names\n",
    "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[text_column_name])\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     outputs =  tokenizer(example[text_column_name], truncation=True, padding='max_length')\n",
    "#     input_batch = []\n",
    "#     for input_ids in outputs[\"input_ids\"]:\n",
    "#         input_batch.append(input_ids)\n",
    "#     return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "preprocessing_num_workers = None\n",
    "with accelerator.main_process_first():\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=preprocessing_num_workers,\n",
    "        remove_columns=column_names,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2b6b95-f6d0-496b-9b5e-e407d3defe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 1024\n",
    "if block_size is None:\n",
    "    block_size = tokenizer.model_max_length\n",
    "    if block_size > 1024:\n",
    "        # logger.warning(\n",
    "        #     f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
    "        #     \"Picking 1024 instead. You can change that default value by passing --block_size xxx.\"\n",
    "        # )\n",
    "        block_size = 1024\n",
    "else:\n",
    "    if block_size > tokenizer.model_max_length:\n",
    "        # logger.warning(\n",
    "        #     f\"The block_size passed ({args.block_size}) is larger than the maximum length for the model\"\n",
    "        #     f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"\n",
    "        # )\n",
    "        block_size = min(block_size, tokenizer.model_max_length)\n",
    "    \n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f33cbf-1736-4fb6-b53a-4c43de02f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2405\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 255\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a remainder\n",
    "# # for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value might be slower\n",
    "# # to preprocess.\n",
    "# #\n",
    "# # To speed up this part, we use multiprocessing. See the documentation of the map method for more information:\n",
    "# # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map\n",
    "preprocessing_num_workers = 1\n",
    "with accelerator.main_process_first():\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        num_proc=preprocessing_num_workers,\n",
    "        desc=f\"Grouping texts in chunks of {block_size}\",\n",
    "    )\n",
    "lm_datasets.set_format(\"torch\")\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87e1364-08f9-4843-955c-328bfab5bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = lm_datasets[\"train\"].shuffle(seed=55) #.select(range(100))\n",
    "small_eval_dataset = lm_datasets[\"validation\"].shuffle(seed=55) #.select(range(10))\n",
    "small_test_dataset = lm_datasets[\"test\"].shuffle(seed=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa8573-15f6-4a1d-ab30-942a0ccd0074",
   "metadata": {},
   "source": [
    "## 3. Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e56875b-ad57-4d47-b414-b35c9086ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=per_device_train_batch_size, pin_memory=True)\n",
    "val_dataloader = DataLoader(small_eval_dataset, batch_size=per_device_eval_batch_size, pin_memory=True)\n",
    "test_dataloader = DataLoader(small_test_dataset, batch_size=per_device_eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f5c3e1-b546-41ee-903b-fe109763229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n"
     ]
    }
   ],
   "source": [
    "#checking chucking\n",
    "for i in train_dataloader:\n",
    "    print(i['input_ids'].shape, i['labels'].shape)\n",
    "    break\n",
    "for i in val_dataloader:\n",
    "    print(i['input_ids'].shape, i['labels'].shape)\n",
    "    break\n",
    "for i in test_dataloader:\n",
    "    print(i['input_ids'].shape, i['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562a75d-8e10-4596-a4cf-ee30ea7d46cc",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30273d86-90b7-4770-8f7f-58cfd7c877ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = AutoConfig.from_pretrained(model_checkpoint, tie_word_embeddings=False)\n",
    "# model = AutoModelForCausalLM.from_config(config)\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95deac2-18b4-44ad-8319-7154f348ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b4dfc0-a038-46f8-9cb3-9c2b50f71d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d347649e-0b0f-494b-bb90-96e3e3c1c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Config, GPT2LMHeadModel\n",
    "# Define the configuration for the student model\n",
    "teacher_config = GPT2Config(\n",
    "    vocab_size=50257,    # Example vocabulary size\n",
    "    n_positions=1024,    # Example sequence length\n",
    "    n_embd=768,         # Adjust the embedding dimension to match teacher's\n",
    "    n_layer=48,  # Number of student layers\n",
    ")\n",
    "\n",
    "# Initialize the student model architecture\n",
    "teacher_model = GPT2LMHeadModel(config=teacher_config)\n",
    "teacher_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82bc059f-b92c-4526-8b5d-f0aa1ff88fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a configuration for a 48-layer GPT2 model\n",
    "# teacher = 'gpt2-xl'\n",
    "# teacher_config = AutoConfig.from_pretrained(teacher)#, tie_word_embeddings=False)\n",
    "# teacher_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     teacher,\n",
    "#     config=teacher_config,\n",
    "# )\n",
    "# teacher_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6a85c2d-9737-441f-8a97-863f518241e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 8, 16, 31, 39, 47]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def pseudo_uniform_selection(n, k):\n",
    "    # Require: n > k; n mod k = 0; n mod 2 = 0\n",
    "    # assert n > k and n % k == 0 and n % 2 == 0, \"Invalid input\"\n",
    "    \n",
    "    step = math.floor(n / k)\n",
    "    start = 0\n",
    "    end = n - 1\n",
    "    selection = []\n",
    "    while start <= end:\n",
    "        selection.append(start)\n",
    "        selection.append(end)\n",
    "        start += step\n",
    "        end -= step\n",
    "    selection.sort()\n",
    "    return selection\n",
    "\n",
    "# Select the layers to copy from the teacher model\n",
    "teacher_layers = teacher_model.config.n_layer\n",
    "student_layers = 6\n",
    "teacher_layers_to_use = pseudo_uniform_selection(teacher_layers, student_layers)\n",
    "print(teacher_layers_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dea5ab5-1056-4a82-a4d1-492837dca806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the layers to copy from the teacher model\n",
    "# teacher_layers_to_use = [num for num in range(teacher_model.config.n_layer) if num % 8 == 0]  # Indices of layers to copy\n",
    "# print(len(teacher_layers_to_use))\n",
    "\n",
    "# Define the configuration for the student model\n",
    "student_config = GPT2Config(\n",
    "    vocab_size=50257,    # Example vocabulary size\n",
    "    n_positions=1024,    # Example sequence length\n",
    "    n_embd=768,         # Adjust the embedding dimension to match teacher's\n",
    "    n_layer=len(teacher_layers_to_use),  # Number of student layers\n",
    ")\n",
    "\n",
    "# Initialize the student model architecture\n",
    "student_model = GPT2LMHeadModel(config=student_config)\n",
    "\n",
    "# Copy teacher layers to student\n",
    "for student_layer_idx, teacher_layer_idx in enumerate(teacher_layers_to_use):\n",
    "    teacher_layer = teacher_model.transformer.h[teacher_layer_idx]\n",
    "    student_layer = student_model.transformer.h[student_layer_idx]\n",
    "    student_layer.load_state_dict(teacher_layer.state_dict())\n",
    "\n",
    "# Now you can use the student model for further tasks\n",
    "student_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99e46760-0cc5-4fed-8a18-fc2be303b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a configuration for a 12-layer GPT2 model\n",
    "# student = \"gpt2\"\n",
    "# student_config = AutoConfig.from_pretrained(student) #, tie_word_embeddings=False)\n",
    "# student_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     student,\n",
    "#     config=student_config,\n",
    "# )\n",
    "# student_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7911fa8f-434e-4e5d-b006-f26d6749efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "weight_decay = 0\n",
    "teacher_optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in teacher_model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in teacher_model.named_parameters()\n",
    "            if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "student_optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in student_model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in student_model.named_parameters()\n",
    "            if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "# params=model.parameters()\n",
    "teacher_optimizer = torch.optim.Adam(teacher_optimizer_grouped_parameters, lr=1e-4)\n",
    "student_optimizer = torch.optim.Adam(student_optimizer_grouped_parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e24aa5-54ff-401f-8a9d-5faf85e2951a",
   "metadata": {},
   "source": [
    "## Accelator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8efcca86-4044-46f8-9b53-102e989b4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare everything with our `accelerator`.\n",
    "# model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "#     model, optimizer, train_dataloader, eval_dataloader\n",
    "# )\n",
    "teacher_model = accelerator.prepare(teacher_model)\n",
    "student_model, student_optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    student_model, student_optimizer, train_dataloader, val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e16bb899-22e0-4b23-8277-997e098aed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "import math\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "num_update_steps_per_epoch = math.ceil(\n",
    "        len(train_dataloader) / gradient_accumulation_steps\n",
    "    )\n",
    "num_train_epochs = 10\n",
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "teacher_lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=teacher_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_train_steps,\n",
    ")\n",
    "\n",
    "student_lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=student_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_train_steps,\n",
    ")\n",
    "\n",
    "total_batch_size = (\n",
    "        per_device_train_batch_size\n",
    "        * accelerator.num_processes\n",
    "        * gradient_accumulation_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ac844-07e3-4e07-ba18-af682334e941",
   "metadata": {},
   "source": [
    "## Ghost clipping: memory saving differentially private learning\n",
    "Turning on ghost clipping requires changing only 1 line. You should notice a drastic reduction in peak GPU memory usage once this is turned on, at a potential cost of slower training speed. One might find this especially useful when constrained to only use older GPUs with small VRAMs or fitting super large models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0491606b-a435-4762-a64d-3dfbf32ae52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ml_swissknife\n",
    "# !pip install opt_einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a38adf0c-31be-49f3-9492-9beda48b6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers, torch\n",
    "from private_transformers import PrivacyEngine\n",
    "dp = False\n",
    "if dp == True:\n",
    "    #student_model\n",
    "    privacy_engine = PrivacyEngine(\n",
    "        student_model,\n",
    "        batch_size=per_device_train_batch_size,\n",
    "        sample_size=len(lm_datasets['train']),\n",
    "        epochs=1,\n",
    "        max_grad_norm=0.1,\n",
    "        target_epsilon=3,\n",
    "        clipping_mode=\"ghost\",  # The only change you need to make!\n",
    "    )\n",
    "    privacy_engine.attach(student_optimizer)\n",
    "    #Teacher Model\n",
    "    privacy_engine = PrivacyEngine(\n",
    "        teacher_model,\n",
    "        batch_size=per_device_train_batch_size,\n",
    "        sample_size=len(lm_datasets['train']),\n",
    "        epochs=per_device_train_batch_size,\n",
    "        max_grad_norm=0.1,\n",
    "        target_epsilon=3,\n",
    "        clipping_mode=\"ghost\",  # The only change you need to make!\n",
    "    )\n",
    "    privacy_engine.attach(teacher_optimizer)\n",
    "\n",
    "else :\n",
    "    privacy_engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc08c72-7595-441d-a856-3fa7140d4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40cb8a11-ffee-48e5-810e-9399d0e31281",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1.0/42061 # We instead use the accountant from Gopi et al. (2021) as described in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd5fa8-9915-4dbc-a8bd-d1a607e95da8",
   "metadata": {},
   "source": [
    "### Loss Objective \n",
    "The Kullback-Leibler divergence loss. For tensors of the same shape $y_{pred}, y_{true}$ where $y_{pred}$ is the input and $y_{true}$ ​ is the target, we define the pointwise KL-divergence as \n",
    "\n",
    "$$L(y_{pred}, y_{true}) = y_{pred}\\cdot \\log \\frac{y_{true}}{y_{pred}}  = y_{true} \\cdot (\\log y_{true} -\\log y_{true})$$\n",
    "\n",
    "format : torch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean', log_target=False)\n",
    "more infomation click [link](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fb8f25b-2d3c-447b-b1c2-0fe1dba45dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(student_outputs, labels, teacher_outputs, alpha = 0.1, T = 1, batch_size = per_device_train_batch_size):\n",
    "    \"\"\"\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! See Issue #2\n",
    "    \"\"\"\n",
    "    # student_outputs.logits.shape = (batch_size, seq_len, vocab_size)\n",
    "    # teacher_outputs.logits.shape = (batch_size, seq_len, vocab_size)\n",
    "    # labels.shape = (batch_size, seq_len)\n",
    "\n",
    "    # Define loss functions (Cross-Entropy for student, KL Divergence for distillation)\n",
    "    student_loss_fn = nn.CrossEntropyLoss()\n",
    "    distillation_loss_fn = nn.KLDivLoss()\n",
    "\n",
    "    # Flatten the logits and targets\n",
    "    student_logits_flat = student_outputs.logits.view(-1, student_outputs.logits.size(-1))\n",
    "    labels_flat = labels.view(-1)\n",
    "    # student_logits_flat shape = (batch_size * seq_len, vocab_size)\n",
    "    # labels_flat shape = (batch_size * seq_len, )\n",
    "\n",
    "    # Calculate Cross-Entropy loss for student\n",
    "    student_loss = student_loss_fn(student_logits_flat, labels_flat)\n",
    "\n",
    "    # Calculate distillation loss (using KL Divergence)\n",
    "    distillation_loss = distillation_loss_fn(\n",
    "        torch.log_softmax(student_logits_flat/T, dim=-1),\n",
    "        torch.softmax(teacher_outputs.logits.view(-1, teacher_outputs.logits.size(-1))/T, dim=-1)* (T ** 2)\n",
    "    )\n",
    "    \n",
    "    # Combine the two losses (you can adjust the weighting factor)\n",
    "    total_loss = (1-alpha)* student_loss + alpha * distillation_loss #label smoothing\n",
    "    print('student_loss', student_loss) \n",
    "    print('distillation_loss', distillation_loss)\n",
    "    # print('total_loss',total_loss)\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4246ffd-21f0-4fab-9436-860f06807136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.total/float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "379c6dcc-0232-4501-9ef2-bfbe3878ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining train_kd & train_and_evaluate_kd functions\n",
    "def train_kd(student_model, teacher_model, optimizer, train_dataloader):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = RunningAverage()\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs_student_batch = student_model(**batch)\n",
    "        labels_batch = batch['labels']\n",
    "        \n",
    "        # get one batch output from teacher_outputs list\n",
    "        with torch.no_grad():\n",
    "            output_teacher_batch = teacher_model(**batch)\n",
    "            \n",
    "        loss = loss_fn_kd(outputs_student_batch, labels_batch, output_teacher_batch)\n",
    "        # loss = outputs_student_batch.loss\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        # loss = loss.reshape(-1)\n",
    "        # accelerator.backward(loss)\n",
    "        if (\n",
    "            step % gradient_accumulation_steps == 0\n",
    "            or step == len(train_dataloader) - 1\n",
    "        ):\n",
    "            # Perform one optimization step with the PrivacyEngine\n",
    "            if dp:\n",
    "                optimizer.step(loss=loss)\n",
    "            else:\n",
    "                accelerator.backward(loss)\n",
    "                optimizer.step()\n",
    "            student_lr_scheduler.step()\n",
    "            # optimizer.zero_grad()\n",
    "            # progress_bar.update(1)\n",
    "            # completed_steps += 1\n",
    "\n",
    "        # if completed_steps >= max_train_steps:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adaabe00-7713-41af-83cd-9b091c492044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kd(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(\n",
    "            accelerator.gather(loss.repeat(per_device_eval_batch_size))\n",
    "        )\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(small_eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return perplexity, torch.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5e08b0c-8dc4-41a2-8843-0ce70f0456b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.KLDivLoss(reduction=\"none\") \n",
    "# distillation_loss = distillation_loss_fn(\n",
    "#             torch.log_softmax(student_outputs, dim=-1),\n",
    "#             torch.softmax(teacher_outputs, dim=-1)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ca82643-f339-4c3e-8c95-2e00798fa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_kd(student_model, teacher_model, train_dataloader, val_dataloader, optimizer, save_path, restore_file=None):\n",
    "    # Only show the progress bar once on each machine.\n",
    "    # progress_bar = tqdm(\n",
    "    #     range(max_train_steps), disable=not accelerator.is_local_main_process\n",
    "    # )\n",
    "    # completed_steps = 0\n",
    "    best_val_perplexity = float(\"inf\")\n",
    "    \n",
    "    for epoch in range(num_train_epochs):\n",
    "        # compute number of batches in one epoch (one full pass over the training set)\n",
    "        train_kd(student_model, teacher_model, optimizer, train_dataloader)\n",
    "        \n",
    "        # Evaluate for one epoch on validation set\n",
    "        perplexity, loss = evaluate_kd(student_model, val_dataloader)\n",
    "\n",
    "        # logger.info(f\"epoch {epoch}: perplexity: {perplexity}\")\n",
    "        print(f\"epoch {epoch}: perplexity: {perplexity} : loss {loss}\")\n",
    "    \n",
    "        if dp:\n",
    "            # Printing epsilon from opacus privacy engine at the end of each epoch\n",
    "            eps, alpha = optimizer.privacy_engine.get_privacy_spent(delta)\n",
    "            print(\"End of epoch {}, we have epsilon {} for alpha {}\".format(epoch, eps, alpha))\n",
    "    \n",
    "        if perplexity < best_val_perplexity and save_path is not None:\n",
    "            best_val_perplexity = perplexity\n",
    "            \n",
    "            print(f\"saved model! epoch {epoch}: perplexity: {best_val_perplexity}\")\n",
    "            # torch.save(student_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b0b47-5cc4-4380-b998-9e8ff458519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/301 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(8.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1345e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/301 [00:01<07:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(7.3910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.4652e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/301 [00:02<06:46,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(7.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.7436e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/301 [00:04<06:30,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(7.5291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(1.7392e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/301 [00:05<06:22,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(6.4207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7906e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/301 [00:06<06:18,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(5.7539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(1.3059e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/301 [00:07<06:14,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(5.6416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(1.3344e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/301 [00:09<06:13,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(4.8405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(1.7833e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/301 [00:10<06:11,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(4.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(1.9325e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/301 [00:11<06:09,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(4.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.0683e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/301 [00:12<06:08,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(4.4880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.0418e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/301 [00:14<06:07,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(4.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.2938e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/301 [00:15<06:06,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.9951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.2856e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/301 [00:16<06:04,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.8194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.4705e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/301 [00:17<06:03,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.5399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.6384e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 15/301 [00:19<06:03,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.4722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.6464e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/301 [00:20<06:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.3308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.7087e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/301 [00:21<06:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.1312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.8432e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/301 [00:23<05:59,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(3.0781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.8237e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/301 [00:24<05:59,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.9647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.8635e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/301 [00:25<05:57,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.9070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.8837e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/301 [00:26<05:57,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.7380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.9036e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/301 [00:28<05:55,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.5957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.0156e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/301 [00:29<05:55,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.5049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.0505e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/301 [00:30<05:53,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.4033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.1493e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/301 [00:31<05:53,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.3724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.0560e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 26/301 [00:33<05:51,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.4015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.9595e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/301 [00:34<05:50,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.3158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(2.9585e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/301 [00:35<05:49,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.1533e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/301 [00:37<05:48,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.0923e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 30/301 [00:38<05:47,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(2.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.1276e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/301 [00:39<05:45,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.9546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.2829e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/301 [00:40<05:44,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.9588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.1648e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/301 [00:42<05:43,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.8671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.2914e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 34/301 [00:43<05:42,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.7186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.4513e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/301 [00:44<05:41,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.6743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.5078e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/301 [00:46<05:40,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.6348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.5667e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/301 [00:47<05:39,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.6564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.5279e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 38/301 [00:48<05:38,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.4967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.6168e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 39/301 [00:49<05:36,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.5161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.5447e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/301 [00:51<05:36,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.4503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.6028e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 41/301 [00:52<05:34,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.3807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.7697e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/301 [00:53<05:34,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.3936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.6849e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/301 [00:55<05:32,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.2832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.8915e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/301 [00:56<05:31,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.2678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.8823e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 45/301 [00:57<05:30,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.2098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.9482e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 46/301 [00:58<05:29,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.2618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(3.8763e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 47/301 [01:00<05:28,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.0919e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/301 [01:01<05:27,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.0901e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 49/301 [01:02<05:25,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.0484e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/301 [01:04<05:24,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.3017e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/301 [01:05<05:23,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(1.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.0208e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/301 [01:06<05:22,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.9704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.2636e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/301 [01:08<05:21,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.9601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.2060e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 54/301 [01:09<05:19,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.9784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.2319e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/301 [01:10<05:18,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.9580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.2517e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 56/301 [01:11<05:16,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.9284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.3285e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/301 [01:13<05:15,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.8436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.4893e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 58/301 [01:14<05:14,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.8786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.4665e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 59/301 [01:15<05:13,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.8139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.5345e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 60/301 [01:17<05:11,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.8027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.5755e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 61/301 [01:18<05:10,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.7404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.6832e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 62/301 [01:19<05:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.7701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.6828e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 63/301 [01:21<05:08,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.7501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.6630e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 64/301 [01:22<05:07,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.7040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.7416e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 65/301 [01:23<05:06,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.7494e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 66/301 [01:24<05:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.7084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.9225e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 67/301 [01:26<05:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.8182e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 68/301 [01:27<05:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.7967e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 69/301 [01:28<05:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.8879e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 70/301 [01:30<05:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.8330e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 71/301 [01:31<04:59,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.0079e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 72/301 [01:32<04:59,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(4.9295e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 73/301 [01:34<04:57,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.0086e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 74/301 [01:35<04:56,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.0681e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 75/301 [01:36<04:54,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.0332e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 76/301 [01:37<04:53,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.0341e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 77/301 [01:39<04:51,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.0506e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 78/301 [01:40<04:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.2107e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 79/301 [01:41<04:48,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.2883e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/301 [01:43<04:47,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.2859e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/301 [01:44<04:45,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.2916e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 82/301 [01:45<04:45,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.3219e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/301 [01:47<04:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.5456e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/301 [01:48<04:42,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.2880e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 85/301 [01:49<04:41,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.3313e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 86/301 [01:50<04:40,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.3864e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/301 [01:52<04:39,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.3954e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 88/301 [01:53<04:37,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.5838e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 89/301 [01:54<04:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.7045e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 90/301 [01:56<04:34,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.4964e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 91/301 [01:57<04:33,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.6755e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/301 [01:58<04:31,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.5893e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 93/301 [02:00<04:31,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.7176e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 94/301 [02:01<04:29,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.4042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.7227e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/301 [02:02<04:28,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.7799e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/301 [02:03<04:27,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.7628e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/301 [02:05<04:25,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.6957e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 98/301 [02:06<04:24,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.7973e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 99/301 [02:07<04:23,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.8114e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/301 [02:09<04:22,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.9052e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/301 [02:10<04:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.8990e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/301 [02:11<04:19,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.8165e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 103/301 [02:13<04:18,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.9164e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/301 [02:14<04:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.9816e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 105/301 [02:15<04:15,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(5.8255e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 106/301 [02:17<04:14,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.0380e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 107/301 [02:18<04:12,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.0124e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 108/301 [02:19<04:11,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.0505e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 109/301 [02:20<04:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.0907e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 110/301 [02:22<04:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.2265e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 111/301 [02:23<04:07,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1486e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/301 [02:24<04:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1963e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/301 [02:26<04:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1679e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 114/301 [02:27<04:04,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1357e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 115/301 [02:28<04:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1456e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 116/301 [02:30<04:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.1847e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/301 [02:31<04:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.2101e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 118/301 [02:32<03:59,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.3067e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 119/301 [02:33<03:57,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.3680e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 120/301 [02:35<03:56,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.2758e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 121/301 [02:36<03:55,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.4395e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 122/301 [02:37<03:54,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.3882e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 123/301 [02:39<03:52,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.3522e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 124/301 [02:40<03:51,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.4386e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/301 [02:41<03:49,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.2555e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/301 [02:43<03:48,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.3255e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 127/301 [02:44<03:47,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.4622e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 128/301 [02:45<03:45,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.5341e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 129/301 [02:47<03:44,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.5324e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 130/301 [02:48<03:43,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.4361e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 131/301 [02:49<03:42,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.5793e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/301 [02:50<03:40,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.6194e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 133/301 [02:52<03:39,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.5862e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 134/301 [02:53<03:37,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.6880e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 135/301 [02:54<03:36,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.6869e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 136/301 [02:56<03:35,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.6662e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 137/301 [02:57<03:34,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.6695e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 138/301 [02:58<03:33,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.2054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.7151e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 139/301 [03:00<03:31,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.7143e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 140/301 [03:01<03:30,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.7795e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/301 [03:02<03:28,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.8544e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 142/301 [03:04<03:27,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.8093e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/301 [03:05<03:25,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.7973e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 144/301 [03:06<03:25,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.8371e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 145/301 [03:07<03:23,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.9465e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 146/301 [03:09<03:22,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.7754e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 147/301 [03:10<03:21,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.8648e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 148/301 [03:11<03:20,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.9412e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 149/301 [03:13<03:18,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.9449e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 150/301 [03:14<03:17,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.8751e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 151/301 [03:15<03:16,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0007e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 152/301 [03:17<03:14,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.9945e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 153/301 [03:18<03:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(6.8476e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 154/301 [03:19<03:11,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0663e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 155/301 [03:21<03:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0881e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/301 [03:22<03:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0803e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 157/301 [03:23<03:08,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0372e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 158/301 [03:24<03:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0326e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 159/301 [03:26<03:05,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.1871e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 160/301 [03:27<03:04,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.2041e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 161/301 [03:28<03:03,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.0730e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 162/301 [03:30<03:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.2837e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 163/301 [03:31<03:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.1435e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 164/301 [03:32<02:58,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.1953e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 165/301 [03:34<02:57,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.1172e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 166/301 [03:35<02:56,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.2058e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 167/301 [03:36<02:55,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.1913e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 168/301 [03:38<02:53,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.2863e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 169/301 [03:39<02:52,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.2847e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 170/301 [03:40<02:51,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.3021e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 171/301 [03:41<02:50,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.3605e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 172/301 [03:43<02:48,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.3307e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 173/301 [03:44<02:47,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4002e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 174/301 [03:45<02:46,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.3120e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 175/301 [03:47<02:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.2805e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 176/301 [03:48<02:43,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4096e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 177/301 [03:49<02:41,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4532e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 178/301 [03:51<02:40,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4754e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 179/301 [03:52<02:38,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4373e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 180/301 [03:53<02:37,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4841e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 181/301 [03:55<02:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5689e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 182/301 [03:56<02:34,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5230e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 183/301 [03:57<02:33,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5229e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 184/301 [03:58<02:32,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5116e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 185/301 [04:00<02:30,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5277e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 186/301 [04:01<02:29,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5436e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 187/301 [04:02<02:28,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.6297e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 188/301 [04:04<02:26,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5301e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 189/301 [04:05<02:25,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.4926e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 190/301 [04:06<02:24,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7073e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 191/301 [04:08<02:23,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.6980e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 192/301 [04:09<02:21,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.6077e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 193/301 [04:10<02:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7246e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 194/301 [04:11<02:19,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.5669e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 195/301 [04:13<02:18,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.6593e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 196/301 [04:14<02:17,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.6691e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 197/301 [04:15<02:15,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7202e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 198/301 [04:17<02:14,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.6958e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 199/301 [04:18<02:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7734e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 200/301 [04:19<02:11,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7690e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/301 [04:21<02:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7530e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 202/301 [04:22<02:09,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7599e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 203/301 [04:23<02:07,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7817e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 204/301 [04:24<02:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8298e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 205/301 [04:26<02:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7851e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 206/301 [04:27<02:04,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9053e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/301 [04:28<02:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.7691e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 208/301 [04:30<02:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8618e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 209/301 [04:31<02:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8679e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 210/301 [04:32<01:58,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8926e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 211/301 [04:34<01:57,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8680e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 212/301 [04:35<01:56,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9160e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 213/301 [04:36<01:55,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8961e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 214/301 [04:38<01:53,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.8420e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 215/301 [04:39<01:52,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9916e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 216/301 [04:40<01:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9502e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 217/301 [04:41<01:49,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0091e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 218/301 [04:43<01:48,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9418e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/301 [04:44<01:47,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0446e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 220/301 [04:45<01:46,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9937e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 221/301 [04:47<01:44,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0864e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 222/301 [04:48<01:43,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(7.9955e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 223/301 [04:49<01:42,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0171e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 224/301 [04:51<01:40,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0514e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 225/301 [04:52<01:39,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.1732e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 226/301 [04:53<01:38,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.1111e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 227/301 [04:55<01:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0586e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 228/301 [04:56<01:35,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2333e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 229/301 [04:57<01:33,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0914e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 230/301 [04:58<01:32,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.0716e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 231/301 [05:00<01:31,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.1772e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 232/301 [05:01<01:29,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.1756e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 233/301 [05:02<01:28,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2520e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 234/301 [05:04<01:27,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.1765e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 235/301 [05:05<01:26,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2300e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 236/301 [05:06<01:24,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2233e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 237/301 [05:08<01:23,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2252e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 238/301 [05:09<01:22,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2593e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 239/301 [05:10<01:20,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.1992e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 240/301 [05:12<01:19,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2374e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 241/301 [05:13<01:18,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2826e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 242/301 [05:14<01:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.2523e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 243/301 [05:15<01:15,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.3482e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 244/301 [05:17<01:14,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.3295e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 245/301 [05:18<01:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4138e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 246/301 [05:19<01:11,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4114e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 247/301 [05:21<01:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.3588e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 248/301 [05:22<01:09,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.3795e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 249/301 [05:23<01:07,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4861e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 250/301 [05:25<01:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4531e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 251/301 [05:26<01:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.3914e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 252/301 [05:27<01:04,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.3886e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 253/301 [05:28<01:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4041e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 254/301 [05:30<01:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4782e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 255/301 [05:31<01:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4889e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 256/301 [05:32<00:58,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5019e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 257/301 [05:34<00:57,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4452e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 258/301 [05:35<00:56,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4969e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 259/301 [05:36<00:54,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4098e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 260/301 [05:38<00:53,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5283e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/301 [05:39<00:52,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4735e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 262/301 [05:40<00:50,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5425e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 263/301 [05:42<00:49,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4284e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 264/301 [05:43<00:48,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.4811e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 265/301 [05:44<00:47,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5290e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 266/301 [05:45<00:45,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5047e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 267/301 [05:47<00:44,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5705e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 268/301 [05:48<00:44,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5671e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 269/301 [05:50<00:42,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5994e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 270/301 [05:51<00:41,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5739e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 271/301 [05:52<00:39,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6105e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 272/301 [05:53<00:37,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5347e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 273/301 [05:55<00:36,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5059e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 274/301 [05:56<00:35,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.5994e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 275/301 [05:57<00:34,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6108e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/301 [05:59<00:32,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7201e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 277/301 [06:00<00:31,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6924e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 278/301 [06:01<00:30,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6216e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 279/301 [06:03<00:28,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7488e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 280/301 [06:04<00:27,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7003e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 281/301 [06:05<00:26,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7012e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 282/301 [06:06<00:24,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7038e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 283/301 [06:08<00:23,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8137e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 284/301 [06:09<00:22,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6872e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 285/301 [06:10<00:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6629e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 286/301 [06:12<00:19,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8157e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 287/301 [06:13<00:18,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8071e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 288/301 [06:14<00:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6823e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 289/301 [06:16<00:15,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7557e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 290/301 [06:17<00:14,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7747e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 291/301 [06:18<00:12,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7210e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 292/301 [06:19<00:11,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.6271e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 293/301 [06:21<00:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7342e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 294/301 [06:22<00:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8667e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 295/301 [06:23<00:07,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8186e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 296/301 [06:25<00:06,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8599e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 297/301 [06:26<00:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8115e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 298/301 [06:27<00:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.7566e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 299/301 [06:29<00:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8656e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 300/301 [06:30<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8240e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [06:31<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: perplexity: 9916841.442980865 : loss 16.109745025634766\n",
      "saved model! epoch 0: perplexity: 9916841.442980865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/301 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.9527e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/301 [00:01<06:30,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.9187e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/301 [00:02<06:30,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8710e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/301 [00:03<06:29,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8470e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/301 [00:05<06:27,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.9240e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/301 [00:06<06:25,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.9391e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/301 [00:07<06:24,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.9984e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/301 [00:09<06:23,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.8872e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/301 [00:10<06:22,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(8.9973e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/301 [00:11<06:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(9.0170e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/301 [00:13<06:20,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(9.0128e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/301 [00:14<06:18,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_loss tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "distillation_loss tensor(9.0662e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/301 [00:16<06:32,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>save_path = <span style=\"color: #808000; text-decoration-color: #808000\">f'models/{</span>student_model.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}_distill_nodp.pt'</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 train_and_evaluate_kd(student_model, teacher_model, train_dataloader, val_dataloader, st     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_and_evaluate_kd</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(num_train_epochs):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># compute number of batches in one epoch (one full pass over the training set)</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>11 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>train_kd(student_model, teacher_model, optimizer, train_dataloader)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Evaluate for one epoch on validation set</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>perplexity, loss = evaluate_kd(student_model, val_dataloader)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_kd</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># get one batch output from teacher_outputs list</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output_teacher_batch = teacher_model(**batch)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = loss_fn_kd(outputs_student_batch, labels_batch, output_teacher_batch)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># loss = outputs_student_batch.loss</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1075</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1073 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1074 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1075 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>transformer_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer(                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>past_key_values=past_key_values,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1078 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">899</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 896 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>encoder_attention_mask,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 897 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 898 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 899 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>outputs = block(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 900 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 901 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>layer_past=layer_past,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 902 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>attention_mask=attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">389</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 386 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>) -&gt; Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 387 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>residual = hidden_states                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 388 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_1(hidden_states)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 389 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 390 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hidden_states,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 391 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>layer_past=layer_past,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 392 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">330</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 327 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reorder_and_upcast_attn:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 328 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attn_output, attn_weights = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._upcast_and_reordered_attn(query, key, valu  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 329 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 330 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attn_output, attn_weights = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._attn(query, key, value, attention_mask, he  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 331 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 332 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._merge_heads(attn_output, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_heads, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.head_dim)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 333 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.c_proj(attn_output)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_attn</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>mask_value = torch.finfo(attn_weights.dtype).min                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Need to be a tensor, otherwise we get error: `RuntimeError: expected scala</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Need to be on the same device, otherwise `RuntimeError: ..., x and y to be</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_we  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype),  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 203 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> attention_mask <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0msave_path = \u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mmodels/\u001b[0m\u001b[33m{\u001b[0mstudent_model.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m_distill_nodp.pt\u001b[0m\u001b[33m'\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 train_and_evaluate_kd(student_model, teacher_model, train_dataloader, val_dataloader, st     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain_and_evaluate_kd\u001b[0m:\u001b[94m11\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(num_train_epochs):                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# compute number of batches in one epoch (one full pass over the training set)\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m11 \u001b[2m│   │   \u001b[0mtrain_kd(student_model, teacher_model, optimizer, train_dataloader)                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Evaluate for one epoch on validation set\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0mperplexity, loss = evaluate_kd(student_model, val_dataloader)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain_kd\u001b[0m:\u001b[94m17\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# get one batch output from teacher_outputs list\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 \u001b[2m│   │   │   \u001b[0moutput_teacher_batch = teacher_model(**batch)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   │   \u001b[0mloss = loss_fn_kd(outputs_student_batch, labels_batch, output_teacher_batch)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# loss = outputs_student_batch.loss\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m1075\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1072 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1073 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1074 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1075 \u001b[2m│   │   \u001b[0mtransformer_outputs = \u001b[96mself\u001b[0m.transformer(                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values=past_key_values,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1078 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m899\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 896 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_attention_mask,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 897 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 898 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 899 \u001b[2m│   │   │   │   \u001b[0moutputs = block(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 900 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 901 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlayer_past=layer_past,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 902 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=attention_mask,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m389\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 386 \u001b[0m\u001b[2m│   \u001b[0m) -> Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 387 \u001b[0m\u001b[2m│   │   \u001b[0mresidual = hidden_states                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 388 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.ln_1(hidden_states)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 389 \u001b[2m│   │   \u001b[0mattn_outputs = \u001b[96mself\u001b[0m.attn(                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 390 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 391 \u001b[0m\u001b[2m│   │   │   \u001b[0mlayer_past=layer_past,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 392 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m330\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 327 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.reorder_and_upcast_attn:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 328 \u001b[0m\u001b[2m│   │   │   \u001b[0mattn_output, attn_weights = \u001b[96mself\u001b[0m._upcast_and_reordered_attn(query, key, valu  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 329 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 330 \u001b[2m│   │   │   \u001b[0mattn_output, attn_weights = \u001b[96mself\u001b[0m._attn(query, key, value, attention_mask, he  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 331 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 332 \u001b[0m\u001b[2m│   │   \u001b[0mattn_output = \u001b[96mself\u001b[0m._merge_heads(attn_output, \u001b[96mself\u001b[0m.num_heads, \u001b[96mself\u001b[0m.head_dim)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 333 \u001b[0m\u001b[2m│   │   \u001b[0mattn_output = \u001b[96mself\u001b[0m.c_proj(attn_output)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92m_attn\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 197 \u001b[0m\u001b[2m│   │   │   \u001b[0mmask_value = torch.finfo(attn_weights.dtype).min                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 198 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scala\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 199 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 200 \u001b[2m│   │   │   \u001b[0mmask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_we  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 201 \u001b[0m\u001b[2m│   │   │   \u001b[0mattn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype),  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 202 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 203 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m attention_mask \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = f'models/{student_model.__class__.__name__}_distill_nodp.pt'\n",
    "train_and_evaluate_kd(student_model, teacher_model, train_dataloader, val_dataloader, student_optimizer, save_path, restore_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c306b6-c31a-4e8c-97b1-cb47c8a52a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = \"./savemodel/\"\n",
    "# save_path = f'models/{model.__class__.__name__}_add10b.pt'\n",
    "\n",
    "# # Only show the progress bar once on each machine.\n",
    "# progress_bar = tqdm(\n",
    "#     range(max_train_steps), disable=not accelerator.is_local_main_process\n",
    "# )\n",
    "# completed_steps = 0\n",
    "# best_val_perplexity = float(\"inf\")\n",
    "\n",
    "# for epoch in range(num_train_epochs):\n",
    "#     model.train()\n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         loss = loss / gradient_accumulation_steps\n",
    "#         loss = loss.reshape(-1)\n",
    "#         # accelerator.backward(loss)\n",
    "#         if (\n",
    "#             step % gradient_accumulation_steps == 0\n",
    "#             or step == len(train_dataloader) - 1\n",
    "#         ):\n",
    "#             # Perform one optimization step with the PrivacyEngine\n",
    "#             optimizer.step(loss=loss)\n",
    "#             lr_scheduler.step()\n",
    "#             # optimizer.zero_grad()\n",
    "#             progress_bar.update(1)\n",
    "#             completed_steps += 1\n",
    "\n",
    "#         if completed_steps >= max_train_steps:\n",
    "#             break\n",
    "\n",
    "#     model.eval()\n",
    "#     losses = []\n",
    "#     for step, batch in enumerate(eval_dataloader):\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**batch)\n",
    "\n",
    "#         loss = outputs.loss\n",
    "#         losses.append(\n",
    "#             accelerator.gather(loss.repeat(per_device_eval_batch_size))\n",
    "#         )\n",
    "\n",
    "#     losses = torch.cat(losses)\n",
    "#     losses = losses[: len(small_eval_dataset)]\n",
    "#     try:\n",
    "#         perplexity = math.exp(torch.mean(losses))\n",
    "#     except OverflowError:\n",
    "#         perplexity = float(\"inf\")\n",
    "\n",
    "#     # logger.info(f\"epoch {epoch}: perplexity: {perplexity}\")\n",
    "#     print(f\"epoch {epoch}: perplexity: {perplexity}\")\n",
    "\n",
    "#     # Printing epsilon from opacus privacy engine at the end of each epoch\n",
    "#     eps, alpha = optimizer.privacy_engine.get_privacy_spent(delta)\n",
    "#     print(\"End of epoch {}, we have epsilon {} for alpha {}\".format(epoch, eps, alpha))\n",
    "\n",
    "#     if perplexity < best_val_perplexity and output_dir is not None:\n",
    "#         best_val_perplexity = perplexity\n",
    "#     #     accelerator.wait_for_everyone()\n",
    "#     #     unwrapped_model = accelerator.unwrap_model(model)\n",
    "#     #     unwrapped_model.save_pretrained(\n",
    "#     #         output_dir, save_function=accelerator.save\n",
    "#     #     )\n",
    "#         # logger.info(\n",
    "#         #     f\"saved model! epoch {epoch}: perplexity: {best_val_perplexity}\"\n",
    "#         # )\n",
    "#         print(f\"saved model! epoch {epoch}: perplexity: {best_val_perplexity}\")\n",
    "#         torch.save(model.state_dict(), save_path)\n",
    "#         # tokenizer.save_pretrained(output_dir)\n",
    "#         # if accelerator.is_main_process:\n",
    "#         #     # tokenizer.save_pretrained(output_dir)\n",
    "#         #     if push_to_hub:\n",
    "#         #         repo.push_to_hub(\n",
    "#         #             commit_message=\"Best val perplexity\", auto_lfs_prune=True\n",
    "#         #         )\n",
    "\n",
    "#     # if push_to_hub and epoch < num_train_epochs - 1:\n",
    "#     #     accelerator.wait_for_everyone()\n",
    "#     #     unwrapped_model = accelerator.unwrap_model(model)\n",
    "#     #     unwrapped_model.save_pretrained(\n",
    "#     #         output_dir, save_function=accelerator.save\n",
    "#     #     )\n",
    "#     #     if accelerator.is_main_process:\n",
    "#     #         tokenizer.save_pretrained(output_dir)\n",
    "#     #         repo.push_to_hub(\n",
    "#     #             commit_message=f\"Training in progress epoch {epoch}\",\n",
    "#     #             blocking=False,\n",
    "#     #             auto_lfs_prune=True,\n",
    "#     #         )\n",
    "\n",
    "#     # if epoch == (num_train_epochs - 1):\n",
    "#     #     save_fir = output_dir + f\"_epoch_{num_train_epochs - 1}\"\n",
    "#     #     accelerator.wait_for_everyone()\n",
    "#     #     unwrapped_model = accelerator.unwrap_model(model)\n",
    "#     #     unwrapped_model.save_pretrained(save_fir, save_function=accelerator.save)\n",
    "#     #     tokenizer.save_pretrained(save_fir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa0a0e-30d9-47ae-9f6b-1c33187d6e50",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b670759-2f28-43f7-9ad4-47ab1474ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = f'models/{model.__class__.__name__}_add10b.pt'\n",
    "# model.load_state_dict(torch.load(save_path,  map_location=device))\n",
    "# perplexity = evaluate(model, test_dataloader)\n",
    "# print(f'Test Perplexity: {perplexity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc9ebe-4cf9-4317-bdc6-739991b53838",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc4c68-5629-4bb3-b8e0-8ce2356e045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import (\n",
    "#     CONFIG_MAPPING,\n",
    "#     MODEL_MAPPING,\n",
    "#     AdamW,\n",
    "#     AutoConfig,\n",
    "#     AutoModelForCausalLM,\n",
    "#     AutoTokenizer,\n",
    "#     default_data_collator\n",
    "# )\n",
    "# from itertools import chain\n",
    "\n",
    "# # Load the trained model\n",
    "# # model_path = 'dp-gpt2-clm-model.pth'\n",
    "# model_checkpoint = \"gpt2\"\n",
    "# config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "# model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "# save_path = f'models/{student_model.__class__.__name__}_distill_nodp.pt'\n",
    "# model.load_state_dict(torch.load(save_path))\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2385acc-efd7-4e5f-a6d1-7db4cbf14d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a92f16-6ff2-4843-a6c4-8200bceb6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tokenizer.encode('My ID is ', return_tensors='pt').to(device)\n",
    "# input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63bdfe-ae9c-4736-b092-da25c010327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_interval = 10\n",
    "# max_seq_len = 200\n",
    "# temperature = 1\n",
    "\n",
    "def generate(prompt, max_seq_len, temperature, model, tokenizer, device, seed=None):\n",
    "    tokens = \"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    with open('nodp-distill-gpt2-generated.txt', 'w') as output_files:\n",
    "        model.eval()\n",
    "        with torch.no_grad():  # no tracking history\n",
    "            for i in range(max_seq_len):\n",
    "                \n",
    "                output = model(input_ids)\n",
    "                word_weights = output[0].squeeze().div(temperature).exp().cpu()\n",
    "                word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "                word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
    "                input = torch.cat([input_ids, word_tensor], 1)\n",
    "    \n",
    "                word = tokenizer.decode(word_idx)\n",
    "                tokens = tokens + word + ('\\n' if i % 20 == 19 else '')\n",
    "                output_files.write(word + ('\\n' if i % 20 == 19 else ''))\n",
    "    \n",
    "                # if i % log_interval == 0:\n",
    "                #     print('| Generated {}/{} words'.format(i, max_seq_len))\n",
    "            # print(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f039560-e5d2-470b-b0a3-9b03ec43b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'my number is'\n",
    "max_seq_len = 10\n",
    "seed = 0\n",
    "temperatures = [0.5, 0.7, 0.75, 0.8, 1.0]\n",
    "for temperature in temperatures:\n",
    "    generation = generate(prompt, max_seq_len, temperature, model, tokenizer, device, seed)\n",
    "    print(f'{str(temperature)}\\n{generation}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
