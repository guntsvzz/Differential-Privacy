{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f78d7e-6cba-4581-ba21-396b891bcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "import os\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dcf49d-f391-4d68-8fb2-55c20993eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "# Set the random seed for reproducible experiments\n",
    "random.seed(230)\n",
    "torch.manual_seed(230)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f40b1f-cdf0-4b1e-b861-935193dd254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71123a62-9d7d-4c7a-9dc0-a143831e62a2",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f6a23c-313f-42e8-b6f9-299b216bfee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1305.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "task_name = \"sst2\"\n",
    "datasets = load_dataset(\"glue\",task_name)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86804cb-74f6-4af1-b653-2cffe678489b",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2143274-5d4e-4162-a9bd-21a5f51ab34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = \"distilroberta-base\"\n",
    "teacher = \"textattack/roberta-base-SST-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72428bba-c315-403a-8b9c-8ece0ebd58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fe74fa-f7b6-4cc4-9fb9-b877dab17711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "if task_name is not None:\n",
    "    is_regression = task_name == \"stsb\"\n",
    "    if not is_regression:\n",
    "        label_list = datasets[\"train\"].features[\"label\"].names\n",
    "        num_labels = len(label_list)\n",
    "    else:\n",
    "        num_labels = 1\n",
    "else:\n",
    "    # Trying to have good defaults here, don't hesitate to tweak to your needs.\n",
    "    is_regression = datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]\n",
    "    if is_regression:\n",
    "        num_labels = 1\n",
    "    else:\n",
    "        # A useful fast method:\n",
    "        # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n",
    "        label_list = datasets[\"train\"].unique(\"label\")\n",
    "        label_list.sort()  # Let's sort it for determinism\n",
    "        num_labels = len(label_list)\n",
    "        \n",
    "num_labels, is_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e138b11-ae14-4f2d-8b2f-ddf26adc8997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer, PretrainedConfig\n",
    "model_name_or_path = student\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    num_labels=num_labels, \n",
    "    finetuning_task=task_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16dd2573-875b-4f33-8ee0-145c20d02fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ddce3eb30c7f5991.arrow\n",
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b7071d8f4a273937.arrow\n",
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f6295d5d5b5292a7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id = None\n",
    "\n",
    "if (\n",
    "    model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id\n",
    "    and task_name is not None\n",
    "    and not is_regression\n",
    "):\n",
    "    # Some have all caps in their config, some don't.\n",
    "    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "    if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):\n",
    "        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "        \n",
    "elif task_name is None and not is_regression:\n",
    "    label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "    \n",
    "def tokenize_function(examples):\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "    args = (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    result = tokenizer(*args, max_length=180, padding=\"max_length\", truncation=True)\n",
    "    if \"label\" in examples:\n",
    "        if label_to_id is not None:\n",
    "            # Map labels to IDs (not necessary for GLUE tasks)\n",
    "            result[\"label\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "        else:\n",
    "            # In all cases, rename the column to labels because the model will expect that.\n",
    "            result[\"label\"] = examples[\"label\"]\n",
    "    \n",
    "    return result\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325561b4-c5d7-442c-a86a-416eca81f956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use list comprehension to extract non-None elements from the tuple\n",
    "elements = [element for element in task_to_keys[task_name] if element is not None]\n",
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8539923-b0fd-481a-8368-1844f0cca755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(elements + [\"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6453ca4-ce3e-4c0d-a00b-5d40149aa8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-29e16e0eef6a27c5.arrow\n",
      "Loading cached shuffled indices for dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b1f20420ff6bc4cb.arrow\n",
      "Loading cached shuffled indices for dataset at /home/todsavadt/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-051ba530f8f9dec6.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation_matched\" if task_name == \"mnli\" else \"validation\"].shuffle(seed=42) #.select(range(100))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226a185-81be-4739-8ff3-3c023666a9be",
   "metadata": {},
   "source": [
    "## 3. Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a8b307-358d-46e2-a7ed-43a2d4e5bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "per_device_train_batch_size = 16\n",
    "per_device_eval_batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=per_device_train_batch_size)\n",
    "val_dataloader = DataLoader(small_eval_dataset, batch_size=per_device_eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132e82f-eb15-40b9-b054-74c80307fdb7",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "690800f2-e6cb-4275-941b-af67554f943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# teacher model\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# student model\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "student_model = student_model.to(device)\n",
    "teacher_model = teacher_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4be448-249d-4085-9236-25bf7e240eac",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34ef0a-67cb-4e2c-af94-1b5bde9b2199",
   "metadata": {},
   "source": [
    "## Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb93a30-7bed-489b-a89b-b8f08745ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107786e-fd5e-41bc-aad9-d00463382598",
   "metadata": {},
   "source": [
    "## Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b86fbd-090e-4004-aff9-751cebb77da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "student_model, optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    student_model, optimizer, train_dataloader, val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d958e56-2a26-408f-9540-8f078bcae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "import math\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "num_update_steps_per_epoch = math.ceil(\n",
    "        len(train_dataloader) / gradient_accumulation_steps\n",
    "    )\n",
    "\n",
    "num_train_epochs = 3\n",
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_train_steps,\n",
    ")\n",
    "\n",
    "total_batch_size = (\n",
    "        per_device_train_batch_size\n",
    "        * accelerator.num_processes\n",
    "        * gradient_accumulation_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0edd424-bb63-4166-bd09-ad1ab5b792bc",
   "metadata": {},
   "source": [
    "### Loss Objective \n",
    "The Kullback-Leibler divergence loss. For tensors of the same shape $y_{pred}, y_{true}$ where $y_{pred}$ is the input and $y_{true}$ ​ is the target, we define the pointwise KL-divergence as \n",
    "\n",
    "$$L(y_{pred}, y_{true}) = y_{pred}\\cdot \\log \\frac{y_{true}}{y_{pred}}  = y_{true} \\cdot (\\log y_{true} -\\log y_{pred})$$\n",
    "\n",
    "format : torch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean', log_target=False)\n",
    "more infomation click [link](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6819a212-9479-4523-8fb0-d987e99cd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(student_outputs, labels, teacher_outputs, alpha = 0.9, T = 1):\n",
    "    \"\"\"\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! See Issue #2\n",
    "    \"\"\"\n",
    "    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    \n",
    "    loss_logits = loss_fn(F.log_softmax(student_outputs.logits/T, dim=-1),\n",
    "                             F.softmax(teacher_outputs.logits/T, dim=-1) * (T ** 2))\n",
    "    KD_loss = alpha * student_outputs.loss + (1. - alpha) * loss_logits\n",
    "    return KD_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201df04e-462e-4023-aa24-5134c4ad08ac",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7fb233-a506-4c3e-9521-653172fe573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the accuracy, given the outputs and labels for all images.\n",
    "\n",
    "    Args:\n",
    "        outputs: (np.ndarray) output of the model\n",
    "        labels: (np.ndarray) [0, 1, ..., num_classes-1]\n",
    "\n",
    "    Returns: (float) accuracy in [0,1]\n",
    "    \"\"\"\n",
    "    # outputs = np.argmax(outputs, axis=1)\n",
    "    return np.sum(outputs==labels)/float(labels.size)\n",
    "\n",
    "\n",
    "# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    # could add more metrics such as accuracy for each token type\n",
    "}\n",
    "\n",
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.total/float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd8b6dd-6405-4f58-9c0a-98edb7c61dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining train_kd & train_and_evaluate_kd functions\n",
    "def train_kd(student_model, teacher_model, optimizer, loss_fn_kd, train_dataloader, metrics):\n",
    "    # set model to training mode\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = RunningAverage()\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        # batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # compute model output, fetch teacher output, and compute KD loss\n",
    "        output_batch = student_model(**batch) # output = loss, logits, hidden_states, attentions\n",
    "        labels_batch = batch['labels']\n",
    "        \n",
    "        # get one batch output from teacher_outputs list\n",
    "        with torch.no_grad():\n",
    "            output_teacher_batch = teacher_model(**batch)\n",
    "\n",
    "        loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch)\n",
    "\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate summaries only once in a while\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            # extract data from torch Variable, move to cpu, convert to numpy arrays            \n",
    "            output_batch = output_batch.logits.argmax(dim=-1).cpu().numpy()\n",
    "            labels_batch = labels_batch.cpu().numpy()\n",
    "\n",
    "            # compute all metrics on this batch\n",
    "            summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
    "                             for metric in metrics}\n",
    "            summary_batch['loss'] = loss.item()\n",
    "            summ.append(summary_batch)\n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        \n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd82c856-03a6-44bf-976b-476009adc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kd(model, eval_dataloader, metrics):\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    # summary for current eval loop\n",
    "    summ = []\n",
    "\n",
    "    # compute metrics over the dataset\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        \n",
    "        # compute model output\n",
    "        output_batch = model(**batch)\n",
    "        labels_batch = batch['labels']\n",
    "        \n",
    "        loss = 0.0  #force validation loss to zero to reduce computation time\n",
    "\n",
    "        # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.logits.argmax(dim=-1).cpu().numpy()\n",
    "        labels_batch = labels_batch.cpu().numpy()\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        # summary_batch['loss'] = loss.item()\n",
    "        summary_batch['loss'] = loss\n",
    "        summ.append(summary_batch)\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    print(\"- Eval metrics : \" + metrics_string)\n",
    "    return metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9627fc09-d25d-41ae-a93b-66dfb40e4135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = './experiments'\n",
    "os.path.exists(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa1143b5-df9c-4298-8d5b-4d54c463f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_kd(student_model, teacher_model, train_dataloader, val_dataloader, \n",
    "                          optimizer, loss_fn_kd, metrics, model_dir, restore_file=None):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_train_epochs):\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "         # compute number of batches in one epoch (one full pass over the training set)\n",
    "        train_kd(student_model, teacher_model, optimizer, loss_fn_kd, train_dataloader,\n",
    "                 metrics)\n",
    "\n",
    "        # Evaluate for one epoch on validation set\n",
    "        val_metrics = evaluate_kd(student_model, val_dataloader, metrics)\n",
    "\n",
    "        val_acc = val_metrics['accuracy']\n",
    "        is_best = val_acc>=best_val_acc\n",
    "\n",
    "        # Save weights\n",
    "        utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optim_dict' : optimizer.state_dict()},\n",
    "                               is_best=is_best,\n",
    "                               checkpoint=model_dir)\n",
    "\n",
    "        # If best_eval, best_save_path\n",
    "        if is_best:\n",
    "            print(\"- Found new best accuracy\")\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "            # Save best val metrics in a json file in the model directory\n",
    "            best_json_path = os.path.join(model_dir, \"metrics_val_best_weights.json\")\n",
    "            utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "        # Save latest val metrics in a json file in the model directory\n",
    "        last_json_path = os.path.join(model_dir, \"metrics_val_last_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, last_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "362ef57a-6203-414e-ab3d-7a4579218dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.485 ; loss: 0.000\n",
      "Checkpoint Directory exists! \n",
      "- Found new best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.485 ; loss: 0.000\n",
      "Checkpoint Directory exists! \n",
      "- Found new best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.485 ; loss: 0.000\n",
      "Checkpoint Directory exists! \n",
      "- Found new best accuracy\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_kd(student_model, teacher_model, train_dataloader, val_dataloader, optimizer,\n",
    "                       loss_fn_kd, metrics, model_dir, restore_file=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
