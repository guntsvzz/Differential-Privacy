{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bfc6f0-2123-4f27-ac76-521aeab387d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.3.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import utils\n",
    "from transformers.models.gpt2 import GPT2Tokenizer\n",
    "\n",
    "from scipy.integrate import quad\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from transformers.models.gpt2 import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c204611c-c41b-4dd2-b1f2-cc95e6c56e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanaryDataset(Dataset):\n",
    "    def __init__(self, canary, canary_list, tokenizer):\n",
    "        self.canary = canary\n",
    "        self.canary_list = canary_list\n",
    "        self.data = self.build_data()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def build_data(self):\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10), desc=\"building the dataset\"):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        for m in range(10):\n",
    "                            for n in range(10):\n",
    "                                # for o in range(10):\n",
    "                                # for p in range(10):\n",
    "                                #     for q in range(10):\n",
    "                                text = f\"My ID is {i}{j}{k}{l}{m}{n}.\"\n",
    "                                texts.append(text)\n",
    "                                encoded_texts.append(tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        for canary in self.canary_list:\n",
    "            assert canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def collate(self, unpacked_data):\n",
    "        return unpacked_data\n",
    "        \n",
    "def load_model_and_tokenizer(model_path, dvice):\n",
    "    config = GPT2Config.from_pretrained(\n",
    "        model_path,\n",
    "    )\n",
    "    config.return_dict = True\n",
    "    config.tie_word_embeddings = False\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "        model_path,\n",
    "    )\n",
    "    model = GPT2LMHeadModel.from_pretrained(\n",
    "        model_path,\n",
    "        config=config,\n",
    "    ).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6562fdde-37b8-4ae6-8913-f6612ba40833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the tokenizer first to create the dataset\n",
    "\n",
    "model_path = \"distilgpt2\"\n",
    "_, tokenizer = load_model_and_tokenizer(model_path, device)\n",
    "PAD_TOKEN_ID = tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee128fbe-9a26-4982-9976-65eaf140520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building the dataset: 100%|██████████| 10/10 [03:23<00:00, 20.34s/it]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# load data\n",
    "###############################################################################\n",
    "CANARY = \"My ID is 341752.\"\n",
    "CANARY_LIST = [\n",
    "    \"My ID is 341752.\",\n",
    "    \"My ID is 151401.\",\n",
    "    \"My ID is 343188.\",\n",
    "    \"My ID is 480519.\",\n",
    "    \"My ID is 203195.\",\n",
    "    \"My ID is 893752.\",\n",
    "    \"My ID is 726839.\",\n",
    "    \"My ID is 861710.\",\n",
    "    \"My ID is 135470.\",\n",
    "    \"My ID is 589883.\",\n",
    "]\n",
    "CANARY_CORPUS = CanaryDataset(CANARY, CANARY_LIST, tokenizer)\n",
    "TOTAL_CANDIDATES = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc2332f4-daa7-4457-a8b8-430495acb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataloader = DataLoader(\n",
    "        dataset=CANARY_CORPUS, shuffle=False, batch_size=batch_size, collate_fn=CANARY_CORPUS.collate\n",
    "    )\n",
    "# [('My ID is 000000.', [3666, 4522, 318, 41853, 13]), .... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "404be463-dd51-412d-ae63-aaa838384222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "\n",
    "def get_model_metrics(model_path):\n",
    "    with open(os.path.join(model_path, \"log_history.json\")) as fh:\n",
    "        log_history = json.load(fh)\n",
    "\n",
    "    result = log_history[-1]\n",
    "    metrics = {\n",
    "        \"valid_ppl\": result[\"val\"][\"model\"][\"ppl\"],\n",
    "        \"test_ppl\": result[\"eval\"][\"model\"][\"ppl\"],\n",
    "    }\n",
    "    print(metrics[\"valid_ppl\"])\n",
    "    metrics.update({k: v for k, v in result.items() if k not in [\"lr\", \"eval\", \"train\", \"val\"]})\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def get_exposure(model, dataloader, save_json=None, multiple_canaries=False):\n",
    "    ###############################################################################\n",
    "    # calculate ppl\n",
    "    ###############################################################################\n",
    "    def calculate_exposure(canary_rank):\n",
    "        return math.log(TOTAL_CANDIDATES, 2) - math.log(canary_rank, 2)\n",
    "\n",
    "    ppls = {}\n",
    "    for batch in tqdm(dataloader, desc=\"batch in get_exposure\"):\n",
    "        batch_text = list(map(lambda x: x[0], batch))\n",
    "        batch_encoded_text = list(map(lambda x: x[1], batch))\n",
    "        batch_ppl = utils.calculate_ppl_gpt2(\n",
    "            batch_encoded_text,\n",
    "            model,\n",
    "            device,\n",
    "            PAD_TOKEN_ID,\n",
    "        )\n",
    "        # import pdb; pdb.set_trace()\n",
    "        ppls.update(dict(zip(batch_text, batch_ppl)))\n",
    "\n",
    "    print(\"sorting...\")\n",
    "    sorted_ppls = {k: (i + 1, v) for i, (k, v) in enumerate(sorted(ppls.items(), key=lambda item: item[1]))}\n",
    "    N = len(sorted_ppls)\n",
    "    if multiple_canaries:\n",
    "        canary_rank, canary_ppl, canary_exposure = [], [], []\n",
    "        for canary in CANARY_LIST:\n",
    "            cur_canary_rank, cur_canary_ppl = sorted_ppls[canary]\n",
    "            canary_rank.append(cur_canary_rank)\n",
    "            canary_ppl.append(cur_canary_ppl)\n",
    "            canary_exposure.append(calculate_exposure(cur_canary_rank))\n",
    "    else:\n",
    "        canary_rank, canary_ppl = sorted_ppls[CANARY]\n",
    "        canary_exposure = calculate_exposure(canary_rank)\n",
    "\n",
    "    # if debug:\n",
    "    #     with open(json_dir, \"w\") as fh:\n",
    "    #         json.dump(sorted_ppls, fh)\n",
    "\n",
    "    print(\"canary exposure\")\n",
    "    print(canary_exposure)\n",
    "    print(\"canary ranking\")\n",
    "    print(canary_rank)\n",
    "\n",
    "    return canary_exposure, canary_rank, canary_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d48a8a-25f8-40f5-8e91-bdbe247c3d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch in get_exposure: 100%|██████████| 31250/31250 [06:32<00:00, 79.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting...\n",
      "canary exposure\n",
      "0.6027074099118472\n",
      "canary ranking\n",
      "658517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_507/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2142997910.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_507/2142997910.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_507/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4022643036.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_model_metrics</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_507/4022643036.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/.local/lib/python3.8/site-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">282</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_modified_open</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 279 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"you can use builtins' open.\"</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 280 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 281 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 282 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> io_open(file, *args, **kwargs)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 283 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 284 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">InteractiveShell</span>(SingletonConfigurable):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 285 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"An enhanced, interactive shell for Python.\"\"\"</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'distilgpt2/log_history.json'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_507/\u001b[0m\u001b[1;33m2142997910.py\u001b[0m:\u001b[94m9\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_507/2142997910.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_507/\u001b[0m\u001b[1;33m4022643036.py\u001b[0m:\u001b[94m5\u001b[0m in \u001b[92mget_model_metrics\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_507/4022643036.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/.local/lib/python3.8/site-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m282\u001b[0m in \u001b[92m_modified_open\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 279 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33myou can use builtins\u001b[0m\u001b[33m'\u001b[0m\u001b[33m open.\u001b[0m\u001b[33m\"\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 280 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 281 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 282 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m io_open(file, *args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 283 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 284 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mInteractiveShell\u001b[0m(SingletonConfigurable):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 285 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"An enhanced, interactive shell for Python.\"\"\"\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'distilgpt2/log_history.json'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiple_canaries = None\n",
    "model, tokenizer = load_model_and_tokenizer(model_path, device)\n",
    "model_path_check = 'dp-gpt2-clm-model.pth'\n",
    "model.load_state_dict(torch.load(model_path_check))\n",
    "\n",
    "canary_exposure, canary_rank, canary_ppl = get_exposure(\n",
    "    model, dataloader, save_json=None, multiple_canaries=multiple_canaries\n",
    ")\n",
    "#this one still error fix later.\n",
    "model_metrics = get_model_metrics(model_path)\n",
    "model_metrics.update(\n",
    "            {\"canary_exposure\": canary_exposure, \"canary_rank\": canary_rank, \"canary_ppl\": canary_ppl}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e23b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\"canary_exposure\": canary_exposure, \"canary_rank\": canary_rank, \"canary_ppl\": canary_ppl}\n",
    "\n",
    "records = []\n",
    "records.append(model_metrics)\n",
    "# records = sorted(records, key = lambda x: x[0])\n",
    "records = pd.DataFrame(\n",
    "    records,\n",
    ")\n",
    "\n",
    "records.to_csv('canary_csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36336f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
