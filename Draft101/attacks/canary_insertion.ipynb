{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bfc6f0-2123-4f27-ac76-521aeab387d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.3.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import utils\n",
    "from transformers.models.gpt2 import GPT2Tokenizer\n",
    "\n",
    "from scipy.integrate import quad\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from transformers.models.gpt2 import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c204611c-c41b-4dd2-b1f2-cc95e6c56e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanaryDataset(Dataset):\n",
    "    def __init__(self, canary, canary_list, tokenizer):\n",
    "        self.canary = canary\n",
    "        self.canary_list = canary_list\n",
    "        self.data = self.build_data()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def build_data(self):\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10), desc=\"building the dataset\"):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        for m in range(10):\n",
    "                            for n in range(10):\n",
    "                                # for o in range(10):\n",
    "                                # for p in range(10):\n",
    "                                #     for q in range(10):\n",
    "                                text = f\"My ID is {i}{j}{k}{l}{m}{n}.\"\n",
    "                                texts.append(text)\n",
    "                                encoded_texts.append(tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        for canary in self.canary_list:\n",
    "            assert canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def collate(self, unpacked_data):\n",
    "        return unpacked_data\n",
    "        \n",
    "def load_model_and_tokenizer(model_path, device):\n",
    "    config = GPT2Config.from_pretrained(\n",
    "        model_path,\n",
    "    )\n",
    "    config.return_dict = True\n",
    "    config.tie_word_embeddings = False\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "        model_path,\n",
    "    )\n",
    "    model = GPT2LMHeadModel.from_pretrained(\n",
    "        model_path,\n",
    "        config=config,\n",
    "    ).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6562fdde-37b8-4ae6-8913-f6612ba40833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the tokenizer first to create the dataset\n",
    "model_path = \"distilgpt2\"\n",
    "_, tokenizer = load_model_and_tokenizer(model_path, device)\n",
    "PAD_TOKEN_ID = tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee128fbe-9a26-4982-9976-65eaf140520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building the dataset: 100%|██████████| 10/10 [03:08<00:00, 18.83s/it]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# load data\n",
    "###############################################################################\n",
    "CANARY = \"My ID is 341752.\"\n",
    "CANARY_LIST = [\n",
    "    \"My ID is 341752.\",\n",
    "    \"My ID is 151401.\",\n",
    "    \"My ID is 343188.\",\n",
    "    \"My ID is 480519.\",\n",
    "    \"My ID is 203195.\",\n",
    "    \"My ID is 893752.\",\n",
    "    \"My ID is 726839.\",\n",
    "    \"My ID is 861710.\",\n",
    "    \"My ID is 135470.\",\n",
    "    \"My ID is 589883.\",\n",
    "]\n",
    "CANARY_CORPUS = CanaryDataset(CANARY, CANARY_LIST, tokenizer)\n",
    "TOTAL_CANDIDATES = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7baf8c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to CanaryDataset.pkl\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# file_name = \"CanaryDataset.pkl\"\n",
    "# with open(file_name, 'wb') as file:\n",
    "#     pickle.dump(CANARY_CORPUS, file)\n",
    "\n",
    "# print(\"Dataset saved to\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b622148b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CanaryDataset at 0x7f270000d190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the file name where the dataset is saved\n",
    "file_name = \"CanaryDataset.pkl\"\n",
    "\n",
    "# Open the file in binary read mode and use pickle.load to load the dataset\n",
    "with open(file_name, 'rb') as file:\n",
    "    CANARY_CORPUS = pickle.load(file)\n",
    "    \n",
    "CANARY_CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2332f4-daa7-4457-a8b8-430495acb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader = DataLoader(\n",
    "        dataset=CANARY_CORPUS, shuffle=False, batch_size=batch_size, collate_fn=CANARY_CORPUS.collate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "404be463-dd51-412d-ae63-aaa838384222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "\n",
    "def get_model_metrics(model_path):\n",
    "    with open(os.path.join(model_path, \"log_history.json\")) as fh:\n",
    "        log_history = json.load(fh)\n",
    "\n",
    "    result = log_history[-1]\n",
    "    metrics = {\n",
    "        \"valid_ppl\": result[\"val\"][\"model\"][\"ppl\"],\n",
    "        \"test_ppl\": result[\"eval\"][\"model\"][\"ppl\"],\n",
    "    }\n",
    "    print(metrics[\"valid_ppl\"])\n",
    "    metrics.update({k: v for k, v in result.items() if k not in [\"lr\", \"eval\", \"train\", \"val\"]})\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def get_exposure(model, dataloader, save_json=None, multiple_canaries=False):\n",
    "    ###############################################################################\n",
    "    # calculate ppl\n",
    "    ###############################################################################\n",
    "    def calculate_exposure(canary_rank):\n",
    "        return math.log(TOTAL_CANDIDATES, 2) - math.log(canary_rank, 2)\n",
    "\n",
    "    ppls = {}\n",
    "    for batch in tqdm(dataloader, desc=\"batch in get_exposure\"):\n",
    "        batch_text = list(map(lambda x: x[0], batch))\n",
    "        batch_encoded_text = list(map(lambda x: x[1], batch))\n",
    "        batch_ppl = utils.calculate_ppl_gpt2(\n",
    "            batch_encoded_text,\n",
    "            model,\n",
    "            device,\n",
    "            PAD_TOKEN_ID,\n",
    "        )\n",
    "        # import pdb; pdb.set_trace()\n",
    "        ppls.update(dict(zip(batch_text, batch_ppl)))\n",
    "\n",
    "    print(\"sorting...\")\n",
    "    sorted_ppls = {k: (i + 1, v) for i, (k, v) in enumerate(sorted(ppls.items(), key=lambda item: item[1]))}\n",
    "    N = len(sorted_ppls)\n",
    "    if multiple_canaries:\n",
    "        canary_rank, canary_ppl, canary_exposure = [], [], []\n",
    "        for canary in CANARY_LIST:\n",
    "            cur_canary_rank, cur_canary_ppl = sorted_ppls[canary]\n",
    "            canary_rank.append(cur_canary_rank)\n",
    "            canary_ppl.append(cur_canary_ppl)\n",
    "            canary_exposure.append(calculate_exposure(cur_canary_rank))\n",
    "    else:\n",
    "        canary_rank, canary_ppl = sorted_ppls[CANARY]\n",
    "        canary_exposure = calculate_exposure(canary_rank)\n",
    "\n",
    "    # if debug:\n",
    "    #     with open(json_dir, \"w\") as fh:\n",
    "    #         json.dump(sorted_ppls, fh)\n",
    "\n",
    "    print(\"canary exposure\")\n",
    "    print(canary_exposure)\n",
    "    print(\"canary ranking\")\n",
    "    print(canary_rank)\n",
    "\n",
    "    return canary_exposure, canary_rank, canary_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1807a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch in get_exposure:  94%|█████████▍| 29484/31250 [05:13<00:19, 89.32it/s]"
     ]
    }
   ],
   "source": [
    "multiple_canaries = None\n",
    "model, tokenizer = load_model_and_tokenizer(model_path, device)\n",
    "model_path_check = 'GPT2LMHeadModel_add10b.pt'\n",
    "model.load_state_dict(torch.load(model_path_check))\n",
    "\n",
    "canary_exposure, canary_rank, canary_ppl = get_exposure(\n",
    "    model, dataloader, save_json=None, multiple_canaries=multiple_canaries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this one still error fix later.\n",
    "# model_metrics = get_model_metrics(model_path)\n",
    "# model_metrics.update(\n",
    "#             {\"canary_exposure\": canary_exposure, \"canary_rank\": canary_rank, \"canary_ppl\": canary_ppl}\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5371964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\"canary_exposure\": canary_exposure, \"canary_rank\": canary_rank, \"canary_ppl\": canary_ppl}\n",
    "\n",
    "records = []\n",
    "records.append(model_metrics)\n",
    "# records = sorted(records, key = lambda x: x[0])\n",
    "records = pd.DataFrame(\n",
    "    records,\n",
    ")\n",
    "\n",
    "records.to_csv('canary_csv_10b.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
