{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d618dbd8-f1ca-4971-8dfb-d7a9ebb89c15",
   "metadata": {},
   "source": [
    "## 1. Extract Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ad6581-9195-4b9f-8a11-aa6e922a9f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "vocabulary = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf895e-4b6a-457f-a7db-ee515e3dde33",
   "metadata": {},
   "source": [
    "## 2.Extract Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c1172a-be1a-48fc-9178-8b741c7b30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "embedding = model.embeddings.word_embeddings.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e119e-7456-40ed-bd12-e3ae815f909f",
   "metadata": {},
   "source": [
    "## 3.Initialize Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f05dfd5-b30a-47a0-b6f4-a1315de16858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b79c61-1e77-43f6-83d1-a7f466efe22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "mdp = metricDP(vocabulary, embedding, start_from=999)\n",
    "mdp.build_ann(metric='euclidean', n_trees=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7af46b-7641-4309-b94b-31351c997c68",
   "metadata": {},
   "source": [
    "## 4.Numeralize Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbd10b-1ceb-47fb-897b-2bc2025a7975",
   "metadata": {},
   "source": [
    "To exclude special tokens from the candidate pool, specifiy the position of regular tokens via start_from. In BERT, the first regular token is '!' at index 999. During the privatization step, each token is remaped from its nearest neighbor item to the embedding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fce70fe-22f5-4759-ac78-5b40f77dfdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat sat on the mat.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'The cat sat on the mat.'\n",
    "ids = tokenizer.encode(txt, truncation=True, padding='max_length', max_length=10)\n",
    "# [101, 1996, 4937, 2938, 2006, 1996, 13523, 1012, 102, 0]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bd82ada-f789-4613-9107-76fcd18e7a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [UNK] [CLS] [SEP] [MASK]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,100,101,102,103])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720e331-895c-4ba0-b9bf-153b142a28a1",
   "metadata": {},
   "source": [
    "## 5. Privatize Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2990cd8-4d69-436d-90f2-0df04ca8e652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1996, 4937, 2938, 2006, 1996, 13523, 1012, 102, 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_ids = mdp.privatize(ids, epsilon=400, special_tokens=[0,100,101,102,103])\n",
    "pv_ids\n",
    "#[101, 2601, 2267, 25195, 20139, 6584, 16304, 22754, 102, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33e18059-593c-4c9e-9908-1537a20ef11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] the cat sat on the mat. [SEP] [PAD]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_txt = tokenizer.decode(pv_ids)\n",
    "pv_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c795f61-f420-4df5-af22-c51ff0c47e3f",
   "metadata": {},
   "source": [
    "Perturbations ignore all tokens specified in special_tokens, and epsilon regulates the privacy guarantees. A smaller epsilon leads to more perturbations and higher privacy guarantees. A higher epsilon leads to less perturbations and lower privacy guarantees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "550147af-4c53-4b46-b1a9-b0eca593cb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s e e m e d'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = 101\n",
    "epsilon = 400\n",
    "random_vec = np.random.normal(size=mdp.embed_dim)\n",
    "normalized_vec = random_vec / np.linalg.norm(random_vec)\n",
    "magnitude = np.random.gamma(shape=mdp.embed_dim, scale=1/epsilon) #high epsilon -> low magnitude\n",
    "noise = normalized_vec * magnitude\n",
    "original_vec = mdp.embedding[token]\n",
    "noisy_vector = original_vec + noise\n",
    "\n",
    "n_trees = 50\n",
    "start_from = 999\n",
    "ann = AnnoyIndex(mdp.embed_dim, 'euclidean')\n",
    "for index, vector in enumerate(mdp.embedding[start_from:,:]):\n",
    "    ann.add_item(index, vector)\n",
    "    \n",
    "ann.build(n_trees)\n",
    "new_token = ann.get_nns_by_vector(noisy_vector, 1)[0]\n",
    "index = new_token + start_from\n",
    "tokenizer.decode(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a5f03-1c75-4c6f-90fa-ae1c88b500a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
